---
title: "Data 624 Project 1"
author: "Stephen Haslett"
date: "10/25/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(caret)
library(tidyr)
library(dplyr)
library(mice)
library(kableExtra)
library(mlbench)
library(forecast)
library(fpp3)
library(DT)
library(feasts)
library(seasonal)
library(tsibble)
library(lubridate)
library(ggplot2)
library(fabletools)
library(fable)
library(tseries)
library(rio)
library(rmarkdown)
```

## Part A – ATM Forecast

**Data File**: _ATM624Data.xlsx_

### Objectives
Forecast how much cash is taken out of 4 different ATM machines for May 2010. The data is given in a single file. The variable ‘Cash’ is provided in hundreds of dollars, other than that it is straight forward. Explain and demonstrate your process, techniques used and not used, and your actual forecast. Please provide your written report on your findings, visuals, discussion and your R code via an RPubs link along with the actual.rmd file. Also please submit the forecast which you will put in an Excel readable file.

\ 

#### Data Analysis And Transformation
**1. Read in the data from the data file and take a look at it's structure.**
```{r readAndCheckData, eval=TRUE, message=FALSE, warning=FALSE}
# Read in the ATM dataset using the rio package's import() function.
ATMData <- import('./data/ATM624Data.xlsx', col_types = c('date', 'text', 'numeric'))

# Look at the raw data.
paged_table(ATMData, options = list(rows.print = 30))
```

A quick inspection of the original data reveals that there are missing values so we will remove these, and also reformat the data so that it is easier to work with.

**2. Clean and reformat the data so that each ATM has it's own column containing the cash withdrawal amounts for that ATM.**
```{r cleanAndReformat, eval=TRUE, message=FALSE, warning=FALSE}
# Drop empty values and reformat the data using the tidyr package's spread() function.
ATMDataFormatted <- ATMData %>% drop_na() %>% spread(ATM, Cash)

# Take a look at the reformatted data.
paged_table(ATMDataFormatted, options = list(rows.print = 30))
```

Now that the data is in a more workable format, we can start preparing to make the forecast.

Looking at the table above, we can see that the greatest amount of cash is withdrawn from **ATM4**, followed by **ATM1** and **ATM2**, with close to zero withdrawals being made from **ATM3** (_ATM3 only has 3 cash withdrawals - 96, 82, and 85 hundred dollars_).

**3. To gain more insight into the data, generate summary statisitics for the data.**
```{r summaryData, eval=TRUE, message=FALSE, warning=FALSE}
summary(ATMDataFormatted)
```

The summary stats reveal that:

- **ATM1** contains **3** NA values.

- **ATM2** contains **2** NA values.

- **ATM4** has one major outlier, a cash withdrawal of **10919.762**. 


**4. In preparation for forecasting, convert the dataset to a timeseries and plot the results so we can gain further insight into the data.**
```{r timeSeriesConversion, eval=TRUE, message=FALSE, warning=FALSE}
# Convert the dataset to a timeseries using the ts() function.
ATMTimeSeries <- ts(ATMDataFormatted %>% select(-DATE))

# Plot the timeseries.
ATMTimeSeries  %>%
  autoplot()  +
  labs(title = 'Daily Cash Withdrawals From ATM1, ATM2, ATM3, and ATM4') +
  scale_y_continuous('Withdrawals In Hundreds of Dollars', labels = scales::dollar_format(scale = 0.1, suffix = 'K')) +
  xlab('Day')
```

Looking at the above plot, we can see that the major outlier for ATM4 may cause issues when forecasting data for this ATM. In order to address this, I will replace that value using the median for ATM4. Additionally, I will also drop the NA values for ATM1 and ATM2. There are so few NA values that I will drop the values rather than risk introducing bias by imputed them with the mean.

```{r outlierReplacement, eval=TRUE, message=FALSE, warning=FALSE}
# Replace ATM4's withdrawal outlier of 10919.761638 (row 1394 in the orginal dataset)
# with the median for that ATM (taken from the summary stats above).
ATMData[1394, 3] <- 403.839

# Now drop the NA values and replot the original data.
ATMData <- ATMData %>% drop_na()
```

In the **_Daily Cash Withdrawals From ATM1, ATM2, ATM3, and ATM4_** plot above, The major outlier in ATM4 prevented us from getting a clear view of the other ATMs. Now that that issue has been addressed, I will replot the original data (_with our fixes applied_) so that we can get a clear view of all 4 ATMs.

```{r dataReplot, eval=TRUE, message=FALSE, warning=FALSE}
ATMData %>% ggplot(aes(x = DATE, y = Cash, col = ATM)) +
  geom_line() +
  facet_wrap(~ATM, ncol = 1, scales = 'free_y') +
  labs(title = 'Cash Withdrawals From ATM1, ATM2, ATM3, and ATM4', subtitle = 'May 2009 through April 2010') +
  scale_y_continuous('Withdrawals In Hundreds of Dollars', labels = scales::dollar_format(scale = 0.1, suffix = 'K')) +
  xlab('Date') 
```

The above plot reveals the following:

- Replacing the outlier in **_ATM4_** with the median has tamed the data, and will hopefully result in a more accurate forecast.

- There are no withdrawals from **_ATM3_** until around the end of _April 2010_. Given the limited amount of data for this ATM, we may not be able to make an accurate forecast for this machine.

- **ATM2** and **ATM1** display seasonality, so we will need to Box-Cox the data in order to build a more accurate forecast model. 

\ 

#### Timeseries and Modeling
Now that we have insight into the data, we can convert it to a time series and work on our ARIMA models in preparation for forecasting. The first step is to convert the entire dataset to a time series and then we will focus on the ARIMA models for each individual ATM machine. 




## Part B – Forecasting Power

**Data File**: _ResidentialCustomerForecastLoad-624.xlsx_

### Objectives
Part B consists of a simple dataset of residential power usage for January 1998 until December 2013. Your assignment is to model these data and a monthly forecast for 2014. The data is given in a single file. The variable ‘KWH’ is power consumption in Kilowatt hours, the rest is straight forward. Add this to your existing files above. 

**1. Read in the data from the data file and take a look at it's structure.**
```{r partBLoadData, eval=TRUE, message=FALSE, warning=FALSE}
residentialPowerUsage <- import('./data/ResidentialCustomerForecastLoad-624.xlsx')
paged_table(residentialPowerUsage, options = list(rows.print = 30))
```

\ 

## Part C – BONUS

**Data Files**: _Waterflow_Pipe1.xlsx, Waterflow_Pipe2.xlsx_

### Objectives
Part C consists of two data sets. These are simple 2 columns sets, however they have different time stamps. Your optional assignment is to time-base sequence the data and aggregate based on hour. Note for multiple recordings within an hour, take the mean. Then to determine if the data is stationary and can it be forecast. If so, provide a week forward forecast and present results via Rpubs and .rmd and the forecast in an Excel readable file.

```{r partC, eval=TRUE, message=FALSE, warning=FALSE}
```