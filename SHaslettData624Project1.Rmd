---
title: "Data 624 Project 1"
author: "Stephen Haslett"
date: "10/25/2021"
output: html_document
---

```{r setup, include=FALSE}
# Convert scientific notation to numbers for readability purposes.
options(scipen = 999)
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(caret)
library(tidyr)
library(dplyr)
library(mice)
library(kableExtra)
library(mlbench)
library(forecast)
library(fpp3)
library(DT)
library(feasts)
library(seasonal)
library(tsibble)
library(lubridate)
library(ggplot2)
library(fabletools)
library(fable)
library(tseries)
library(rio)
library(rmarkdown)
library(urca)
```

## Part A – ATM Forecast

**Data File**: _ATM624Data.xlsx_

### Objectives
Forecast how much cash is taken out of 4 different ATM machines for May 2010. The data is given in a single file. The variable ‘Cash’ is provided in hundreds of dollars, other than that it is straight forward. Explain and demonstrate your process, techniques used and not used, and your actual forecast. Please provide your written report on your findings, visuals, discussion and your R code via an RPubs link along with the actual.rmd file. Also please submit the forecast which you will put in an Excel readable file.

\ 

#### Data Analysis And Transformation
**1. Read in the data from the data file and take a look at it's structure.**
```{r readAndCheckData, eval=TRUE, message=FALSE, warning=FALSE}
# Read in the ATM dataset using the rio package's import() function.
ATMData <- import('./data/ATM624Data.xlsx', col_types = c('date', 'text', 'numeric'))

# Look at the raw data.
paged_table(ATMData, options = list(rows.print = 30))
```

A quick inspection of the original data reveals that there are missing values so we will remove rows with missing values, and also reformat the data so that it is easier to work with.

**2. Clean and reformat the data so that each ATM has it's own column containing the cash withdrawal amounts for that ATM.**

The first order of business is to remove columns that contain empty values. 
```{r cleanRows, eval=TRUE, message=FALSE, warning=FALSE}
# Drop rows containing empty values and plot the data.
ATMData <- ATMData %>% drop_na()

ggplot(ATMData, aes(DATE, Cash)) + geom_line() + facet_grid(ATM~., scales = 'free') +
  labs(title = 'Cash Withdrawals From ATM1, ATM2, ATM3, and ATM4', y = 'Withdrawals in Hundreds of dollars', x = 'Date')
```

The above plot reveals that:

- There are no withdrawals from **_ATM3_** until around the end of _April 2010_. Given the limited amount of data for this ATM, we may not be able to make an accurate forecast for this machine.

- **ATM4** has one major outlier around _March 2010_.

We will now reformat the data so that each ATM has it's own column containing the cash withdrawal amounts for that ATM.

```{r cleanAndReformat, eval=TRUE, message=FALSE, warning=FALSE}
# Reformat the data using the tidyr package's spread() function.
ATMData <- ATMData %>% spread(ATM, Cash)

# Summarize the data after reformatting the data.
summary(ATMData)
```

The above summary of the reformatted data reveals that:

- **ATM1** and **ATM2** contain empty values.

- There is a major outlier for **ATM4** - a cash withdrawal of **10919.762**.

To further refine the data, we will remove the empty values fron ATM1 and ATM2, and also replace ATM4's outlier with the median for that machine's data.

```{r outlierReplacementAndNARemoval, eval=TRUE, message=FALSE, warning=FALSE}
# Replace ATM4's withdrawal outlier of 10919.762 with the median for that ATM.
ATMData$ATM4[ATMData$ATM4==max(ATMData$ATM4)] <- median(ATMData$ATM4)

# Drop rows with empty values for ATM1 and ATM2.
ATMData <- ATMData %>% drop_na()

# Resummarize the data to see the effect of the changes.
summary(ATMData)
```

THe above summary confirms that the NA values have now been removed from ATM1 and ATM2, and the outlier for ATM4 has now been resolved. We will now replot the data to confirm that ATM4's outlier no longer exists.

```{r outlierReplacementConfirmationPlot, eval=TRUE, message=FALSE, warning=FALSE}
# Replot the data to confirm that the outlier for ATM4 has been resolved. 
ATMDataCleaned <- ATMData %>% 
  pivot_longer(cols = starts_with('ATM'), names_to = 'ATM', values_to = 'Cash')

ggplot(ATMDataCleaned, aes(DATE, Cash)) + geom_line() + facet_grid(ATM~., scales = 'free') +
  labs(title = 'Cash Withdrawals From ATM1, ATM2, ATM3, and ATM4', y = 'Withdrawals in Hundreds of dollars', x = 'Date')
```

The above plot confirms that ATM4's outlier no longer exists.

We will now take a look at the reformatted data.

```{r reformattedData, eval=TRUE, message=FALSE, warning=FALSE}
# Take a look at the reformatted data.
paged_table(ATMData, options = list(rows.print = 30))
```

Looking at the table above, we can see that the greatest amount of cash is withdrawn from **ATM4**, followed by **ATM1** and **ATM2**, with close to zero withdrawals being made from **ATM3** (_ATM3 only has 3 cash withdrawals - 96, 82, and 85 hundred dollars_).


#### Timeseries and Modeling
Now that we have insight into the data, we can convert the dataframe into a time series and work on our ARIMA models in preparation for forecasting. The first step is to convert the entire dataset into a time series and then we will focus on the ARIMA models for each individual ATM machine.


```{r timeSeriesConversion, eval=TRUE, message=FALSE, warning=FALSE}
# Convert the dataset to a timeseries using the ts() function.
ATMDataTimeSeries <- ts(ATMData %>% select(-DATE), start = 1, frequency = 7)
```



\ 

##### ATM 1

```{r atmOne, eval=TRUE, message=FALSE, warning=FALSE}
atmOne <- ATMDataTimeSeries[,1]
ggtsdisplay(atmOne,
            main = 'Cash Withdrawals for ATM1',
            ylab = 'Withdrawal Amount ($K)',
            xlab = 'Week')
```

The above series plot for ATM1 displays weekly seasonality. The ACF and PACF plots also contain lags that fall outside of the boundaries suggesting that the data is not white noise.
This tells us that this is a non-stationary series. In order to address the seasonality and variance for ATM1, we will Box-Cox the data.

```{r atmOneBoxCox, eval=TRUE, message=FALSE, warning=FALSE}
# Perform a Box-Cox transformation on the data.
#atmOne <- BoxCox(atmOne, lambda = BoxCox.lambda(atmOne))
#ggtsdisplay(atmOne, main = 'Cash Withdrawals for ATM1 After Box-Cox Transformation')
```

Seasonality still exists after Box-Coxing the data for ATM1. However, the transformation has reduced the amount of variance in the data. In order to reduce the amount of seasonality and achieve stationarity, we will now difference the data.

```{r atmOneDifferencing, eval=TRUE, message=FALSE, warning=FALSE}
# Difference the data and then create a comparision plot so that
# we can see the effects of differencing on the data. 
#atmOne <- diff(atmOne, lag = 7)
ggtsdisplay(atmOne, main = 'ATM1 After Differencing')

# Perform a KPSS unit root test to confirm stationarity.
atmOneKPSSTest <- ur.kpss(atmOne)
summary(atmOneKPSSTest)
```

As we can see from the above series plot, differencing the data has reduced seasonality considerably. Additionally, the results of the KPSS unit root test tell us that the data is now stationary as the critical value is less than 1%.

##### ATM1 ARIMA Modeling
In order to select the most appropriate ARIMA model for forcasting, we will use the auto.arima() function to suggest the best model to use.

```{r atmOneARIMASelection, eval=TRUE, message=FALSE, warning=FALSE}
# Run the series through the auto.arima() function and have it automatically select an appropriate ARIMA model. 
lambda <- BoxCox.lambda(atmOne)
atmOneAutoArimaSelection <- auto.arima(atmOne, lambda = lambda)

# Print out the results of the selection. 
summary(atmOneAutoArimaSelection)
```

The auto.arima() function has selected an ARIMA(2,0,0)(0,1,1)[7] model, so we will use this to forecast how much cash will be taken out of ATM1 in May 2010.


##### ATM1 May 2010 Cash Withdrawal Forecast.

```{r atmOneForecast, eval=TRUE, message=FALSE, warning=FALSE}
# Forecast cash withdrawals form ATM1 during the month of May 2010 and plot the results.
atmOneForecast <- forecast(atmOneAutoArimaSelection, 31, level = 95)
autoplot(atmOneForecast) +
  labs(title = 'ARIMA(2,0,0)(0,1,1)[7] Forecast',
       subtitle = 'Forecast of Cash Withdrawals From ATM1 For The Month of May 2010') +
  scale_y_continuous('Withdrawals In Hundreds of Dollars', labels = scales::dollar_format(scale = 0.1, suffix = 'K')) +
  xlab('Days') 
```

\ 

#### ATM 2
```{r atmTwo, eval=TRUE, message=FALSE, warning=FALSE}
atmTwo <- ATMDataTimeSeries[,2]
ggtsdisplay(atmOne,
            main = 'Cash Withdrawals for ATM2',
            ylab = 'Withdrawal Amount ($K)',
            xlab = 'Week')
```

##### ATM2 ARIMA Modeling
In order to select the most appropriate ARIMA model for forcasting, we will use the auto.arima() function to suggest the best model to use.

```{r atmTwoARIMASelection, eval=TRUE, message=FALSE, warning=FALSE}
# Run the series through the auto.arima() function and have it automatically select an appropriate ARIMA model. 
lambda <- BoxCox.lambda(atmTwo)
atmTwoAutoArimaSelection <- auto.arima(atmTwo, lambda = lambda)

# Print out the results of the selection. 
summary(atmTwoAutoArimaSelection)
```

The auto.arima() function has selected an ARIMA(2,0,0)(0,1,1)[7] model, so we will use this to forecast how much cash will be taken out of ATM2 in May 2010.


##### ATM2 May 2010 Cash Withdrawal Forecast.

```{r atmTwoForecast, eval=TRUE, message=FALSE, warning=FALSE}
# Forecast cash withdrawals form ATM2 during the month of May 2010 and plot the results.
atmTwoForecast <- forecast(atmTwoAutoArimaSelection, 31, level = 95)
autoplot(atmTwoForecast) +
  labs(title = 'ARIMA(3,0,4)(0,1,1)[7] Forecast',
       subtitle = 'Forecast of Cash Withdrawals From ATM2 For The Month of May 2010') +
  scale_y_continuous('Withdrawals In Hundreds of Dollars', labels = scales::dollar_format(scale = 0.1, suffix = 'K')) +
  xlab('Days') 
```


\ 

##### ATM 3
```{r atmThree, eval=TRUE, message=FALSE, warning=FALSE}
atmThree <- ATMDataTimeSeries[,3]
ggtsdisplay(atmThree,
            main = 'Cash Withdrawals for ATM3',
            ylab = 'Withdrawal Amount ($K)',
            xlab = 'Week')

```

There is not enough data for ATM3 to make an accurate forecast model, so we will use the mean to make a forecast.

##### ATM3 May 2010 Cash Withdrawal Forecast.

```{r atmThreeForecast, eval=TRUE, message=FALSE, warning=FALSE}
# Forecast cash withdrawals from ATM3 using the mean during the month of May 2010 and plot the results.
atmThree <- window(atmThree, start = 40)
atmThreeForecast <-meanf(atmThree, 31, level = 95)
autoplot(atmThreeForecast) +
  labs(title = 'Mean Forecast For ATM3') +
  scale_y_continuous('Withdrawals In Hundreds of Dollars', labels = scales::dollar_format(scale = 0.1, suffix = 'K')) +
  xlab('Days') 
```

\ 

##### ATM 4
```{r atmFour, eval=TRUE, message=FALSE, warning=FALSE}
atmFour <- ATMDataTimeSeries[,4]
ggtsdisplay(atmFour,
            main = 'Cash Withdrawals for ATM4',
            ylab = 'Withdrawal Amount ($K)',
            xlab = 'Week')
```

##### ATM4 ARIMA Modeling
In order to select the most appropriate ARIMA model for forcasting, we will use the auto.arima() function to suggest the best model to use.

```{r atmFourARIMASelection, eval=TRUE, message=FALSE, warning=FALSE}
# Run the series through the auto.arima() function and have it automatically select an appropriate ARIMA model. 
lambda <- BoxCox.lambda(atmFour)
atmFourAutoArimaSelection <- auto.arima(atmFour, lambda = lambda)

# Print out the results of the selection. 
summary(atmFourAutoArimaSelection)
```

The auto.arima() function has selected an ARIMA(1,0,1)(2,0,1)[7]] model, so we will use this to forecast how much cash will be taken out of ATM4 in May 2010.


##### ATM4 May 2010 Cash Withdrawal Forecast.

```{r atmFourForecast, eval=TRUE, message=FALSE, warning=FALSE}
# Forecast cash withdrawals form ATM4 during the month of May 2010 and plot the results.
atmFourForecast <- forecast(atmFourAutoArimaSelection, 31, level = 95)
autoplot(atmFourForecast) +
  labs(title = 'ARIMA(1,0,1)(2,0,1)[7] Forecast',
       subtitle = 'Forecast of Cash Withdrawals From ATM4 For The Month of May 2010') +
  scale_y_continuous('Withdrawals In Hundreds of Dollars', labels = scales::dollar_format(scale = 0.1, suffix = 'K')) +
  xlab('Days') 
```

\ 

## Part B – Forecasting Power

**Data File**: _ResidentialCustomerForecastLoad-624.xlsx_

### Objectives
Part B consists of a simple dataset of residential power usage for January 1998 until December 2013. Your assignment is to model these data and a monthly forecast for 2014. The data is given in a single file. The variable ‘KWH’ is power consumption in Kilowatt hours, the rest is straight forward. Add this to your existing files above. 

\ 

#### Data Analysis And Transformation

**1. Read in the data from the data file and take a look at it's structure.**
```{r partBLoadData, eval=TRUE, message=FALSE, warning=FALSE}
residentialPowerUsage <- import('./data/ResidentialCustomerForecastLoad-624.xlsx')
paged_table(residentialPowerUsage, options = list(rows.print = 30))

# Summarize the data.
summary(residentialPowerUsage)
```

**2. Data Transformation**

Looking at the summary of the raw data above, we can see that the **KWH** column contains one empty value, and one major outlier of **770523** KWH. It also looks like the date format will be problematic when plotting and forecasting the data. Before taking care of the empty value and outlier, we will reformating the date format so we can plot the data to inspect it visually.

```{r partBPlotData, eval=TRUE, message=FALSE, warning=FALSE}
# Format the date column into a compatible format.
residentialPowerUsage$`YYYY-MMM` <- paste0(residentialPowerUsage$`YYYY-MMM`, '-01')
residentialPowerUsage$date <- ymd(residentialPowerUsage$`YYYY-MMM`)

# Plot the data.
ggplot(residentialPowerUsage, aes(date, KWH)) + geom_line() + 
  labs(title = 'Residential Power Usage', y = 'KWH', x = 'Time')
```

Th above plot confirms the outlier visually.

To take care of both the missing value and the outlier, I will impute both values with the mean of the data for the month in which they occur.

```{r partBDataTransformation, eval=TRUE, message=FALSE, warning=FALSE}
# The missing value occurs in September, 2008, so imput the missing value with the mean of the data for that month.
residentialPowerUsage$Month <- month(residentialPowerUsage$date)
residentialPowerUsage$KWH[is.na(residentialPowerUsage$KWH)] <- mean(residentialPowerUsage$KWH[residentialPowerUsage$Month == 9], na.rm = TRUE)

# The outlier occurs in July, 2010, so imput the outlier with the mean of the data for that month.
residentialPowerUsage$KWH[residentialPowerUsage$KWH == min(residentialPowerUsage$KWH)] <- mean(residentialPowerUsage$KWH[residentialPowerUsage$Month == 7], na.rm = TRUE)
```


Now that we have imputed the data to take care of both the outlier and the missing value, we will summarize and replot the data to confirm that the issues are indeed resolved.

```{r partBPostImputationPlotAndSummary, eval=TRUE, message=FALSE, warning=FALSE}
# Summarize and plot the data to confirm that both the missing value and outlier have been taken care.
summary(residentialPowerUsage)

# Plot the data after imputation.
ggplot(residentialPowerUsage, aes(date, KWH)) + geom_line() + 
  labs(title = 'Residential Power Usage After Imputation', y = 'KWH', x = 'Time')
```

The above summary and plot confirms that the imputation has taken care of both the missing value, and the outlier.

\ 

#### Timeseries and Modeling
Now that we have cleansed the data, we can convert the data into a time series and work on our ARIMA model in preparation for creating a 2014 monthly forecast.

**1. Convert the data into a time series.**

```{r partBTimeSeriesConversion, eval=TRUE, message=FALSE, warning=FALSE}
# Convert the data to a time series..
residentialPowerUsageTimeSeries <- ts(residentialPowerUsage[,'KWH'], start = c(1998, 1), frequency = 12)
```


**2. Analyze the time series.**

```{r partBTimeSeriesConversion, eval=TRUE, message=FALSE, warning=FALSE}
# Plot the time series data.
autoplot(residentialPowerUsageTimeSeries) +
  labs(title = 'Monthly Residential Power Usage', subtitle = 'January 1998 Through December 2013') +
  ylab('Power Consumed in kWh') +
  xlab('Month') 

```

The above plot reveals that the time series is seasonal, and displays peaks roughly every 6 months. This is probably due to the fact that more electricity is consumed in the winter and summer months. The series also displays an upward trend.

##### ARIMA Modeling
In order to select the most appropriate ARIMA model for forcasting, we will use the auto.arima() function.

```{r partBARIMASelection, eval=TRUE, message=FALSE, warning=FALSE}
# Run the series through the auto.arima() function and have it automatically select an appropriate ARIMA model. 
lambda <- BoxCox.lambda(residentialPowerUsageTimeSeries)
residentialPowerUsageAutoArimaSelection <- auto.arima(residentialPowerUsageTimeSeries, lambda = lambda)

# Print out the results of the selection. 
summary(residentialPowerUsageAutoArimaSelection)
```


The auto.arima() function has selected an ARIMA(0,0,1)(2,1,0)[12] with drif tmodel, so we will use this to create our 2014 monthly power usage forecast.




## Part C – BONUS

**Data Files**: _Waterflow_Pipe1.xlsx, Waterflow_Pipe2.xlsx_

### Objectives
Part C consists of two data sets. These are simple 2 columns sets, however they have different time stamps. Your optional assignment is to time-base sequence the data and aggregate based on hour. Note for multiple recordings within an hour, take the mean. Then to determine if the data is stationary and can it be forecast. If so, provide a week forward forecast and present results via Rpubs and .rmd and the forecast in an Excel readable file.

```{r partC, eval=TRUE, message=FALSE, warning=FALSE}
```